{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7d9d1ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████████████████| 2187/2187 [24:45<00:00,  1.47iteration/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "for item in ['APU0000706111']:\n",
    "    \n",
    "    target=item\n",
    "    path = f'/Users/angelobenedicto/Documents/Commodities Hedger/Commodities/{target}.csv'\n",
    "\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(path, parse_dates=['DATE'], index_col='DATE')\n",
    "    data[target] = pd.to_numeric(data[target], errors='coerce')\n",
    "    data = data['2014':'2023-02-01']\n",
    "    data.interpolate(method='linear', inplace=True)\n",
    "\n",
    "    # Define the p, d, q, and seasonal P, D, Q, S\n",
    "    p = d = q = range(0, 3)\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(product(p, d, q))]\n",
    "\n",
    "    # Temporal Cross Validation sets\n",
    "    n_periods = [6, 9, 12]\n",
    "\n",
    "    # DataFrame to store results\n",
    "    results = pd.DataFrame(columns=['pdq', 'seasonal_pdq', 'hold_out', 'MAPE'])\n",
    "\n",
    "    total_iterations = len(list(product(p, d, q))) * len(seasonal_pdq) * len(n_periods)\n",
    "\n",
    "    # Initialize progress bar\n",
    "    with tqdm(total=total_iterations, desc=\"Progress\", unit=\"iteration\") as pbar:\n",
    "        for pdq in product(p, d, q):\n",
    "            for seasonal in seasonal_pdq:\n",
    "                for hold in n_periods:\n",
    "                    try:\n",
    "                        # Splitting the data\n",
    "                        train = data[:-hold]\n",
    "                        test = data[-hold:]\n",
    "\n",
    "                        # Fit SARIMA Model\n",
    "                        model = SARIMAX(train, order=pdq, seasonal_order=seasonal, enforce_stationarity=False, enforce_invertibility=False)\n",
    "                        model_fit = model.fit(disp=False)\n",
    "\n",
    "                        # Forecast\n",
    "                        predictions = model_fit.get_forecast(steps=hold)\n",
    "                        prediction_values = predictions.predicted_mean\n",
    "\n",
    "                        # Calculate MAPE\n",
    "                        mape = mean_absolute_percentage_error(test, prediction_values)\n",
    "\n",
    "                        # Store results\n",
    "                        results = pd.concat([results, pd.DataFrame({\n",
    "                            'pdq': [pdq],\n",
    "                            'seasonal_pdq': [seasonal],\n",
    "                            'hold_out': [hold],\n",
    "                            'MAPE': [mape]\n",
    "                        })], ignore_index=True)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f'Error: {e} with PDQ {pdq}, Seasonal PDQ {seasonal}, Hold-Out {hold}')\n",
    "\n",
    "                    # Update progress bar\n",
    "                    pbar.update(1)\n",
    "\n",
    "    #Pivot Results\n",
    "    pivot_df = results.pivot_table(index=['pdq', 'seasonal_pdq'], columns='hold_out', values='MAPE', aggfunc='first')\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "    pivot_df['MEAN MAPE'] = pivot_df[[6, 9, 12]].mean(axis=1)\n",
    "    pivot_df.sort_values(by='MEAN MAPE')\n",
    "    pivot_df.to_csv(f'{target}_params_list.csv')\n",
    "\n",
    "    #Get Best Params\n",
    "    best_params = pivot_df.sort_values(by='MEAN MAPE').iloc[0]\n",
    "    best_pdq = best_params['pdq']\n",
    "    best_seasonal_pdq = best_params['seasonal_pdq']\n",
    "\n",
    "    # Fit model using best parameters on entire data set\n",
    "    final_model = SARIMAX(data, order=best_pdq, seasonal_order=best_seasonal_pdq, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    final_model_fit = final_model.fit(disp=False)\n",
    "\n",
    "    # Forecast the next 12 steps\n",
    "    forecast = final_model_fit.get_forecast(steps=12)\n",
    "    forecast_values = forecast.predicted_mean\n",
    "    forecast_values.to_csv(f'{target}_forecast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c62a0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Comm Lookup\n",
    "comm_lookup = pd.read_excel('/Users/angelobenedicto/Documents/Commodities Hedger/Commodities/CommLookUp.xlsx')\n",
    "\n",
    "#Farm Forecasts\n",
    "forecast_df = pd.DataFrame(columns=['DATE', 'FORECAST', 'FRED Ticker'])\n",
    "\n",
    "#Combine DataFrames\n",
    "for item in ['APU0000706111', 'PSMEAUSDM','APU000072610','CES2000000008']:\n",
    "    comm_df = pd.read_csv(f'/Users/angelobenedicto/Documents/GitHub/BarnGPT/Forecasts/{item}_forecast.csv')\n",
    "    comm_df = pd.DataFrame(comm_df)\n",
    "    comm_df['COMM'] = item\n",
    "    comm_df.columns=['DATE', 'FORECAST', 'FRED Ticker']\n",
    "    forecast_df = pd.concat([forecast_df, comm_df], axis=0)\n",
    "                          \n",
    "forecast_df = forecast_df.merge(comm_lookup[['FRED Ticker', 'Code']], how='left', on='FRED Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c5722a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Farm Actuals\n",
    "actuals_df = pd.DataFrame(columns=['DATE', 'ACTUALS', 'FRED Ticker'])\n",
    "\n",
    "#Combine DataFrames\n",
    "for item in ['APU0000706111', 'PSMEAUSDM','APU000072610','CES2000000008']:\n",
    "    comm_df = pd.read_csv(f'/Users/angelobenedicto/Documents/GitHub/BarnGPT/Commodities/{item}.csv')\n",
    "    comm_df = pd.DataFrame(comm_df)\n",
    "    comm_df['COMM'] = item\n",
    "    comm_df.columns=['DATE', 'ACTUALS', 'FRED Ticker']\n",
    "    actuals_df = pd.concat([actuals_df, comm_df], axis=0)\n",
    "\n",
    "actuals_df = actuals_df.merge(comm_lookup[['FRED Ticker', 'Code']], how='left', on='FRED Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ea925cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Forecasts and Actuals to Excel\n",
    "forecast_df.to_excel('forecast.xlsx')\n",
    "actuals_df.to_excel('actuals.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea50c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
